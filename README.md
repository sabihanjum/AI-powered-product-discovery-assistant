# AI-Powered Product Discovery Assistant

A mini AI-powered product discovery assistant that recommends the right products based on open-ended and abstract user queries. Built with FastAPI, React, and Google Gemini AI.

![Product Discovery](https://img.shields.io/badge/AI-Product%20Discovery-blue)
![Python](https://img.shields.io/badge/Python-3.11+-green)
![React](https://img.shields.io/badge/React-18+-61DAFB)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688)

## ðŸŽ¯ Features

- **Smart Product Search**: Uses semantic embeddings to find relevant products
- **AI Chat Assistant**: Natural language product recommendations powered by Google Gemini
- **Web Scraping**: Automated product data collection from e-commerce sites
- **RAG Pipeline**: Retrieval-Augmented Generation for accurate recommendations
- **Modern UI**: Clean React frontend with responsive design
- **Search & Filter**: Client-side product filtering

## ðŸ§  Design Decisions & Assumptions

### Product Thinking

1. **Target Use Case**: Users with vague health concerns (e.g., "I'm losing hair") who need product guidance
2. **Recommendation Strategy**: 
   - Semantic search finds products based on meaning, not just keywords
   - LLM provides human-like explanations for WHY products match
   - Top 3 recommendations to avoid overwhelming users

3. **User Experience Assumptions**:
   - Users may not know exact product names
   - Natural language queries are preferred over filters
   - Quick responses are more important than exhaustive results

### Technical Decisions

1. **SQLite over PostgreSQL**: Simpler setup, sufficient for demo scale (< 1000 products)
2. **sentence-transformers**: Local embeddings for privacy and no API costs
3. **Gemini 2.0 Flash**: Fast, cost-effective LLM for conversational responses
4. **KNN Search**: Simple but effective for small-medium product catalogs
5. **Pre-computed Embeddings**: Embeddings are generated locally and shipped with the database, enabling deployment on memory-constrained platforms (e.g., Render free tier) without loading large ML models at runtime

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontend â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI Backend â”‚â”€â”€â”€â”€â–¶â”‚   SQLite DB     â”‚
â”‚   (Vite + React) â”‚     â”‚   (Python)       â”‚     â”‚   (Products)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼            â–¼            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Scraper  â”‚ â”‚Embeddingsâ”‚ â”‚ Gemini   â”‚
              â”‚(BS4/httpx)â”‚ â”‚(MiniLM)  â”‚ â”‚   API    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Scraping**: BeautifulSoup extracts products â†’ SQLite storage
2. **Embedding**: Product text â†’ 384-dim vectors (MiniLM-L6-v2)
3. **Query**: User message â†’ Embedding â†’ KNN search â†’ Top matches
4. **Response**: Context + Query â†’ Gemini â†’ Natural language recommendation

## Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- Google Gemini API Key ([Get one here](https://makersuite.google.com/app/apikey))

### Backend Setup

```bash
# Navigate to project
cd "AI-powered product discovery assistant"

# Create virtual environment
python -m venv .venv

# Activate (Windows)
.\.venv\Scripts\Activate.ps1

# Activate (Linux/Mac)
source .venv/bin/activate

# Install dependencies
cd backend
pip install -r requirements.txt

# Set up environment variables
# Edit .env file and add your Gemini API key
cp .env.example .env
# GEMINI_API_KEY=your_api_key_here

# Run the backend
uvicorn app.main:app --host 127.0.0.1 --port 8000
```

### Frontend Setup

```bash
# In a new terminal
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

### Access the Application

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## Project Structure

```
AI-powered product discovery assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI app entry
â”‚   â”‚   â”œâ”€â”€ api.py           # API routes
â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas.py       # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ crud.py          # Database operations
â”‚   â”‚   â”œâ”€â”€ database.py      # DB connection
â”‚   â”‚   â”œâ”€â”€ retrieval.py     # Embeddings & search
â”‚   â”‚   â””â”€â”€ llm.py           # Gemini API client
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ scraper.py       # Scraper dispatcher
â”‚   â”‚   â””â”€â”€ traya_scraper.py # Traya.health scraper
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx     # Product grid
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductDetail.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Chat.jsx     # AI chat interface
â”‚   â”‚   â”œâ”€â”€ api.js           # API client
â”‚   â”‚   â””â”€â”€ App.jsx          # Main app
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ðŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/api/products` | List all products |
| GET | `/api/products/{id}` | Get product details |
| POST | `/api/scrape?site=traya` | Run web scraper |
| POST | `/api/chat` | AI chat endpoint |

### Chat API Example

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "I have hair fall problem, what can help?"}'
```

Response:
```json
{
  "message": "Based on your hair fall concerns, I recommend...",
  "recommendations": [
    {
      "product_id": 37,
      "title": "Customized Hair Fall Plans",
      "score": 0.59,
      "reason": "Get custom hair fall solutions..."
    }
  ]
}
```

## How It Works

1. **Web Scraping**: Products are scraped from traya.health using BeautifulSoup and httpx
2. **Embeddings**: Product descriptions are converted to 384-dim vectors using sentence-transformers (all-MiniLM-L6-v2)
3. **Pre-computed Storage**: Embeddings are stored in SQLite and shipped with the deployment for memory efficiency
4. **Semantic Search**: User queries are matched against pre-computed embeddings using enhanced text similarity
5. **RAG Generation**: Top matching products provide context for Gemini to generate personalized recommendations

## Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **SQLAlchemy** - ORM for database operations
- **SQLite** - Lightweight database
- **sentence-transformers** - Text embeddings
- **httpx** - Async HTTP client
- **BeautifulSoup4** - HTML parsing

### Frontend
- **React 18** - UI library
- **Vite** - Build tool
- **React Router** - Navigation
- **Axios** - HTTP client

### AI/ML
- **Google Gemini** - LLM for chat responses
- **all-MiniLM-L6-v2** - Embedding model

## Docker Deployment

```bash
# Build and run
docker-compose up --build

# Access
# Frontend: http://localhost:5173
# Backend: http://localhost:8000
```

## Environment Variables

Create a `.env` file in the `backend/` directory:

```env
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash
DATABASE_URL=sqlite:///./dev.db
```

## ðŸŽ¥ Demo

[Loom Video Demo](YOUR_LOOM_LINK_HERE)

## âš¡ Edge Cases Handled

| Scenario | Handling |
|----------|----------|
| Empty/short query | Returns helpful prompt to user |
| No matching products | Suggests alternative query phrasing |
| LLM API failure | Graceful fallback to template response |
| Invalid product ID | Returns 404 with clear message |
| Scraper timeout | Error handling with retry logic |
| Missing product images | Placeholder image fallback |
| CORS issues | Properly configured for frontend |

## ðŸš€ Extra Features (Beyond Requirements)

1. **Product Search Bar**: Filter products on the home page
2. **Typed API Responses**: Pydantic models for request/response validation
3. **Configurable Recommendations**: `top_k` parameter in chat API
4. **Production Docker Setup**: Separate dev and prod configurations
5. **Nginx Config**: Ready for production deployment
6. **Query Echo**: Returns user's query in response for context

## ðŸ“Š Performance Notes

- **Embedding Model**: ~400MB download on first run, cached thereafter
- **Response Time**: ~2-5 seconds (embedding + LLM call)
- **Concurrent Users**: Handles multiple requests (FastAPI async)

## License

MIT License

---

Built for Neusearch AI Technical Assignment
